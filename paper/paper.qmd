---
title: "Magic Vs Evolution"
subtitle: "Or more specifically language in Harry Potter vs Darwin's Natural Selection"
author: "Shreya Sakura Noskor"
thanks: "Code and data are available at: LINK."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(gutenbergr)
library(pdftools)
library(arrow)
library(dplyr)
library(stringr)
library(rstanarm)
library(marginaleffects)
```


```{r}

darwin <-
  gutenberg_download(
    gutenberg_id = 2009,
    mirror = "https://gutenberg.pglaf.org/"
  )

darwin

write_csv(darwin, "../data/raw_data/darwin.csv")



```


```{r}
harry <- pdf_text("../other/literature/HarryAzkaban.pdf")
class(harry)
harry <- tibble(
  raw_text = harry,
  page_number = c(1:454)
)

harry <- 
  separate_rows(harry, raw_text, sep = "\\n", convert = FALSE)

write_csv(harry, "../data/raw_data/harry.csv")

```


```{r}
darwin <- read_csv(
  "../data/raw_data/darwin.csv",
  col_types = cols(
    gutenberg_id = col_integer(),
    text = col_character()
  )
)



darwin_reduced <- darwin |>
  filter(!is.na(text)) |> 
  mutate(natural_count = str_count(text, regex('natural', ignore_case = T)), 
         magic_count = str_count(text, regex('magic|miracle', ignore_case = T)), 
         word_count = str_count(text, "\\w+"))

write_csv(darwin_reduced, "../data/analysis_data/darwin_reduced.csv")
arrow::write_parquet(darwin_reduced, "../data/analysis_data/darwin_reduced.parquet")
```




# Introduction




# Data {#sec-data}

# Model

## Natural and the 2 texts

Define $y_i$ is the number of times "natural" appeared in the text and the explanatory variable is the number of words in the line.

\begin{align} 
y_i|\lambda_i &\sim \mbox{Poisson}(\lambda_i) \\
\mbox{log}(\lambda_i) &= \beta_0 + \beta_1 \times \mbox{Number } \mbox{of } \mbox{Words}_i\\
\beta_0 &\sim \mbox{Normal}(0, 2.5) \\
\beta_1 &\sim \mbox{Normal}(0, 2.5) \\
\end{align}

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.
```{r}
darwin_nature <-
  stan_glm(
    natural_count ~ word_count,
    data = darwin_reduced,
    family = poisson(link = "log"),
    prior = normal(location = 0, scale = 2.5, autoscale = TRUE),
    prior_intercept = normal(location = 0, scale = 2.5, autoscale = TRUE),
    seed = 853
  )

saveRDS(
  darwin_nature,
  file = "../models/darwin_nature.rds"
)
```

```{r}
plot_predictions(darwin_nature, condition = "word_count") +
  labs(x = "Number of words",
       y = "Average number of \"natural\"s in the first 10 lines") +
  theme_classic()
```
Negative relation it seems




### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.

## "Magic" and the 2 texts
Define $y_i$ is the number of times "magic" or "miracle" appeared in the text and the explanatory variable is the number of words in the line.

\begin{align} 
y_i|\lambda_i &\sim \mbox{Poisson}(\lambda_i) \\
\mbox{log}(\lambda_i) &= \beta_0 + \beta_1 \times \mbox{Number } \mbox{of } \mbox{Words}_i\\
\beta_0 &\sim \mbox{Normal}(0, 2.5) \\
\beta_1 &\sim \mbox{Normal}(0, 2.5) \\
\end{align}

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.


### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.

# Results

Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(rstanarm)

first_model <-
  readRDS(file = here::here("models/first_model.rds"))
```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Explanatory models of flight time based on wing width and wing length"
#| warning: false

modelsummary::modelsummary(
  list(
    "First model" = first_model
  ),
  statistic = "mad",
  fmt = 2
)
```




# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

pp_check(first_model) +
  theme_classic() +
  theme(legend.position = "bottom")

posterior_vs_prior(first_model) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()
```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(first_model, "trace")

plot(first_model, "rhat")
```



\newpage


# References


